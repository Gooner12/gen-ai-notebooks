{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9cf5c18a89f34b7ca7facee516f6ea75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7bd377d82342779c2e197b62130585",
              "IPY_MODEL_adebf09c90044b6abcca1836547d9e73",
              "IPY_MODEL_85689ae6091948c593de017fa9e256e0"
            ],
            "layout": "IPY_MODEL_762dc9c4b3ac449ebe02c38e39fa0df9"
          }
        },
        "be7bd377d82342779c2e197b62130585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c194f26a7fce41fc9cd02f063d3f545d",
            "placeholder": "​",
            "style": "IPY_MODEL_52a58ce961f34b40a0a1d9ee7fc78762",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "adebf09c90044b6abcca1836547d9e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f82ac9194b44ae9ef271f15ffdef76",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f59dadbdd624f30bf5a2039e6fd46ca",
            "value": 26
          }
        },
        "85689ae6091948c593de017fa9e256e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f071973c82a94e52b3ce04d0f6a35867",
            "placeholder": "​",
            "style": "IPY_MODEL_7212e6d03dd9431b84fe49363a1baba7",
            "value": " 26.0/26.0 [00:00&lt;00:00, 796B/s]"
          }
        },
        "762dc9c4b3ac449ebe02c38e39fa0df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c194f26a7fce41fc9cd02f063d3f545d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a58ce961f34b40a0a1d9ee7fc78762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f82ac9194b44ae9ef271f15ffdef76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f59dadbdd624f30bf5a2039e6fd46ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f071973c82a94e52b3ce04d0f6a35867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7212e6d03dd9431b84fe49363a1baba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b93967aa32140739540fed83e332620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed334e7aaa4423680793a9d8b0a4bf7",
              "IPY_MODEL_00d4c258773a45e79d5deacbf7d240d2",
              "IPY_MODEL_62414cbb8f0742589bc26f878df1dff9"
            ],
            "layout": "IPY_MODEL_359c088063904f3ea64ad6b3bbaa79db"
          }
        },
        "fed334e7aaa4423680793a9d8b0a4bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aeea062dd3541c0b88d897453d46a11",
            "placeholder": "​",
            "style": "IPY_MODEL_c857b63697bd4ffca7aa881777a85a21",
            "value": "vocab.json: 100%"
          }
        },
        "00d4c258773a45e79d5deacbf7d240d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f015ddbac334be4b2fe900a52e67edc",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b428eeb217654e2585a4a38d4b655040",
            "value": 1042301
          }
        },
        "62414cbb8f0742589bc26f878df1dff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0187d200ad14b9f9e230677c4882b68",
            "placeholder": "​",
            "style": "IPY_MODEL_40b53401880a4b83bd81c4167f9a9c09",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "359c088063904f3ea64ad6b3bbaa79db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aeea062dd3541c0b88d897453d46a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c857b63697bd4ffca7aa881777a85a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f015ddbac334be4b2fe900a52e67edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b428eeb217654e2585a4a38d4b655040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0187d200ad14b9f9e230677c4882b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b53401880a4b83bd81c4167f9a9c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e174d37fd0c4b329e554e9d92e38755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63987d779af3431b8e4ad1eae4685c5a",
              "IPY_MODEL_2ce771a48465485db7145ad155bcc5c1",
              "IPY_MODEL_5d04f8ac11e2400a91235dbedd9ee7a2"
            ],
            "layout": "IPY_MODEL_9f59c727eb5b4e239aec229593f3feb2"
          }
        },
        "63987d779af3431b8e4ad1eae4685c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e52950efdd994cd8ab0f64819e3bbb1f",
            "placeholder": "​",
            "style": "IPY_MODEL_e037ae48af064da29209294761bd92a7",
            "value": "merges.txt: 100%"
          }
        },
        "2ce771a48465485db7145ad155bcc5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cbb335fefff481786bdda367393f7be",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa3f5d6ee25046d99a2c0d1aebc6a158",
            "value": 456318
          }
        },
        "5d04f8ac11e2400a91235dbedd9ee7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8058e46c59d543bd82d0ff4212fa9728",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4a35a8d44d428d8adf8bc167cf2d69",
            "value": " 456k/456k [00:00&lt;00:00, 15.3MB/s]"
          }
        },
        "9f59c727eb5b4e239aec229593f3feb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52950efdd994cd8ab0f64819e3bbb1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e037ae48af064da29209294761bd92a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cbb335fefff481786bdda367393f7be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3f5d6ee25046d99a2c0d1aebc6a158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8058e46c59d543bd82d0ff4212fa9728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4a35a8d44d428d8adf8bc167cf2d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4f0ed85e4924ebcb6fcdd4be37a7898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bc9c8426631476e86247b069b749b39",
              "IPY_MODEL_fce5e46db1af451bb350290f934139c8",
              "IPY_MODEL_f1fd7d81e44c470085b3c6de193369b8"
            ],
            "layout": "IPY_MODEL_babd3f1009734ae7b21145b9fa12c7ea"
          }
        },
        "6bc9c8426631476e86247b069b749b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f08bf161b34865b58f1962aa56143e",
            "placeholder": "​",
            "style": "IPY_MODEL_dd203959fbdf4922ad66679f4ce0ca85",
            "value": "tokenizer.json: 100%"
          }
        },
        "fce5e46db1af451bb350290f934139c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92205189b2c4674af61e6b1fd72d3fb",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e491fef0ce7b476d8b1fec00b0b94130",
            "value": 1355256
          }
        },
        "f1fd7d81e44c470085b3c6de193369b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1340225a3c84bbb96a9f1970fc287da",
            "placeholder": "​",
            "style": "IPY_MODEL_2c78203f6c4846dea4db8add44c19b88",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 30.5MB/s]"
          }
        },
        "babd3f1009734ae7b21145b9fa12c7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f08bf161b34865b58f1962aa56143e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd203959fbdf4922ad66679f4ce0ca85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e92205189b2c4674af61e6b1fd72d3fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e491fef0ce7b476d8b1fec00b0b94130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1340225a3c84bbb96a9f1970fc287da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c78203f6c4846dea4db8add44c19b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2827ced6067948828b928fec978fe7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7f8d42036b34f58a661f2b56e12a28f",
              "IPY_MODEL_9d4dec11925041639283f8480c273db5",
              "IPY_MODEL_4fb8a321ea5a4910a2551644f60d6c36"
            ],
            "layout": "IPY_MODEL_785318e4c3dc4f74953884296d782b30"
          }
        },
        "d7f8d42036b34f58a661f2b56e12a28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0728a056b524041a5e6432f2f856fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_7512967156314d1ca6a32e4a29c14079",
            "value": "config.json: 100%"
          }
        },
        "9d4dec11925041639283f8480c273db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57374d7da32a48f9a4aa31b7155f5b93",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0cc846564954fceb2d92b0813e40e9c",
            "value": 665
          }
        },
        "4fb8a321ea5a4910a2551644f60d6c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c45cb9cbe14f618d9e3ec5f1a1f23b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f8e5d363aa64e168bab94468d150d55",
            "value": " 665/665 [00:00&lt;00:00, 23.6kB/s]"
          }
        },
        "785318e4c3dc4f74953884296d782b30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0728a056b524041a5e6432f2f856fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7512967156314d1ca6a32e4a29c14079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57374d7da32a48f9a4aa31b7155f5b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0cc846564954fceb2d92b0813e40e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8c45cb9cbe14f618d9e3ec5f1a1f23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8e5d363aa64e168bab94468d150d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain: Conversation Demo"
      ],
      "metadata": {
        "id": "XoJ-RGiUo-uJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSTxnoIozRN",
        "outputId": "add21d23-26ea-458e-9a04-4ae410ddc40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install openai langchain huggingface_hub transformers langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YknUQAhuPi0V",
        "outputId": "15f529bc-19e0-4041-a3e8-a3b745acf1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['BEDROCK_AWS_ACCESS_KEY_ID'] = userdata.get('BEDROCK_AWS_ACCESS_KEY_ID')\n",
        "os.environ['BEDROCK_AWS_SECRET_ACCESS_KEY'] = userdata.get('BEDROCK_AWS_SECRET_ACCESS_KEY')\n",
        "os.environ['BEDROCK_AWS_REGION_SYD'] = userdata.get('BEDROCK_AWS_REGION_SYD')\n",
        "os.environ['BEDROCK_AWS_REGION_USEAST'] = userdata.get('BEDROCK_AWS_REGION_USEAST')"
      ],
      "metadata": {
        "id": "9iIacDfgpB2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import boto3\n",
        "\n",
        "# Define AWS credentials and region\n",
        "aws_access_key_id = userdata.get('BEDROCK_AWS_ACCESS_KEY_ID')\n",
        "aws_secret_access_key = userdata.get('BEDROCK_AWS_SECRET_ACCESS_KEY')\n",
        "profile_name = 'bedrock-runtime'\n",
        "\n",
        "# Create the .aws directory\n",
        "os.makedirs(os.path.expanduser('~/.aws'), exist_ok=True)\n",
        "\n",
        "# Write the credentials file\n",
        "with open(os.path.expanduser('~/.aws/credentials'), 'w') as f:\n",
        "    f.write(f\"[{profile_name}]\\n\")\n",
        "    f.write(f\"aws_access_key_id = {aws_access_key_id}\\n\")\n",
        "    f.write(f\"aws_secret_access_key = {aws_secret_access_key}\\n\")\n",
        "\n",
        "# Set the AWS_PROFILE environment variable\n",
        "os.environ['AWS_PROFILE'] = profile_name"
      ],
      "metadata": {
        "id": "hO56E0PjanLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Basic Conversation with ConversationBufferMemory"
      ],
      "metadata": {
        "id": "-KB9qA8bpxgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This memory allows for storing every conversation happened between a human and a bot. The stored conversation is passed to the bot along with the query to get a response that satisfies the conversation context."
      ],
      "metadata": {
        "id": "wrhRlklkkhz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "-lzO5PfUpwfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Bedrock\n",
        "\n",
        "credentials = os.environ[\"AWS_PROFILE\"]\n",
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 200},\n",
        "    streaming=True,\n",
        ")\n",
        "print(llm)"
      ],
      "metadata": {
        "id": "sTiEn3tKp7mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5396fe3c-9a75-4caf-86ea-1bf0a625f188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mBedrock\u001b[0m\n",
            "Params: {'region_name': 'ap-southeast-2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"System: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
        "The assistant is talkative and provides lots of specific details from its context.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "\n",
        "User: {input}\n",
        "Bot:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "D98z6qGngIWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(human_prefix=\"User\", ai_prefix=\"Bot\")"
      ],
      "metadata": {
        "id": "9EBuodi9wHwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "eF2pCbWqry4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def continue_conversation(user_input):\n",
        "    response = conversation.predict(input=user_input)\n",
        "    return response"
      ],
      "metadata": {
        "id": "NEJp_WXBgUVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Hi there! I am Sam\"\n",
        "response = continue_conversation(user_input)\n",
        "print(\"AI:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5J5r7sAgYs_",
        "outputId": "fb36c354-af4d-468a-f4a8-e3eba589c27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Hi there! I am Sam\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI:  Hello Sam! How may I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"How are you today?\"\n",
        "response = continue_conversation(user_input)\n",
        "print(\"AI:\", response)\n",
        "# conversation.predict(input=\"How are you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tENUfRYVFb4P",
        "outputId": "25a33528-f51e-4f6b-94f6-9b9aa4eb26e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "User: Hi there! I am Sam\n",
            "Bot:  Hello Sam! How may I assist you today?\n",
            "\n",
            "User: How are you today?\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI:  As a Large Language Model (LLM), I don't have feelings and emotions, but thank you for asking. Is there anything else I can assist you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"Can you help me with some customer support?\"\n",
        "response = continue_conversation(user_input)\n",
        "print(\"AI:\", response)\n",
        "# conversation.predict(input=\"I'm good thank you. Can you help me with some customer support?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB3NvFScsRGQ",
        "outputId": "54c11d4d-7ddb-43ce-add0-1de02f132de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "User: Hi there! I am Sam\n",
            "Bot:  Hello Sam! How may I assist you today?\n",
            "User: How are you today?\n",
            "Bot:  As a Large Language Model (LLM), I don't have feelings and emotions, but thank you for asking. Is there anything else I can assist you with?\n",
            "\n",
            "User: Can you help me with some customer support?\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "AI:  Absolutely! How may I help you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NeyECDc-l65",
        "outputId": "76699b82-b9d4-41ab-dbd7-1cbcb9a4f540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hi there! I am Sam\n",
            "Bot:  Hello Sam! How may I assist you today?\n",
            "User: How are you today?\n",
            "Bot:  As a Large Language Model (LLM), I don't have feelings and emotions, but thank you for asking. Is there anything else I can assist you with?\n",
            "User: Can you help me with some customer support?\n",
            "Bot:  Absolutely! How may I help you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Conversation with ConversationSummaryMemory"
      ],
      "metadata": {
        "id": "tdR-2GM_sfEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of storing the whole conversations, a summary of conversation is generated which will be used to provide context to the bot while asking the question."
      ],
      "metadata": {
        "id": "N_pHOtD_k_ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "LLNWdNCpsul3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 200},\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kUbCneqQsumE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_memory = ConversationSummaryMemory(llm=llm)\n"
      ],
      "metadata": {
        "id": "VTaQpp2TsumE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=summary_memory\n",
        ")"
      ],
      "metadata": {
        "id": "wDXSZK7lsumE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Sam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "447437ee-ecea-49bd-8899-66db24a40c46",
        "id": "6QNnwCWCsumF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Hi there! I am Sam\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hi Sam, I am Cookie. I will be assisting you today. How may I help you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"How are you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "c8723b83-ac04-4757-bea9-30ac626fb6d7",
        "id": "pc26jL4utIOW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces themselves as Sam and requests assistance from AI. The AI introduces themselves as Cookie and expresses their readiness to offer support.\n",
            "\n",
            "User: How are you today?\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I'm very well, thank you. How can I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Can you help me with some customer support?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "18395714-18ea-4240-9350-c57944662e15",
        "id": "YXAhBz1ntIOX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human and AI have a conversation where the AI greets the human and asks how they are. The AI confirms that they are ready to provide support.\n",
            "\n",
            "User: Can you help me with some customer support?\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hello. Sure, I can help you with customer support. Please provide me with a description of the issue or question you have, and I'll do my best to assist you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5650459-0796-4eea-e416-7950d5685b0e",
        "id": "94erF8qRtIOX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The human has requested that the AI provides customer support. The AI has confirmed that they are available and will do their best to assist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSYb5x3uJt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Conversation with ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "5ovDKMUttXg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
      ],
      "metadata": {
        "id": "dtP00-uUlXTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "pyY4p8S1tXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 200},\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "jnf_9Ni6tXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set a low k=2, to only keep the last 2 interactions in memory\n",
        "window_memory = ConversationBufferWindowMemory(k=2)"
      ],
      "metadata": {
        "id": "aZhRObxXtXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=window_memory\n",
        ")"
      ],
      "metadata": {
        "id": "qtv7iCSStXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there! I am Sam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "d17d57e5-6c26-4257-d469-394742a19fda",
        "id": "SU9hmumXtXg6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Hi there! I am Sam\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello Sam! How may I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I am looking for some customer support\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0e97ccbc-326b-49aa-8640-d8484cbd5b03",
        "id": "-ANI031otXg6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Sam\n",
            "AI:  Hello Sam! How may I assist you today?\n",
            "\n",
            "User: I am looking for some customer support\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" That's great! How may I assist you with customer support?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"My TV is not working.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "7b85036b-4803-4c5f-e881-a755eb61aa24",
        "id": "xa_Y1vzotXg6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Sam\n",
            "AI:  Hello Sam! How may I assist you today?\n",
            "Human: I am looking for some customer support\n",
            "AI:  That's great! How may I assist you with customer support?\n",
            "\n",
            "User: My TV is not working.\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Ok. It looks like you may have an issue with the power supply or the TV itself. To better assist you, can you tell me the make and model of your TV?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"When I turn it on it makes some weird sounds and then goes black\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "7A4QCtdOuC7D",
        "outputId": "b80c0fc4-e4cc-4c1d-b710-3d5f53985c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "Human: I am looking for some customer support\n",
            "AI:  That's great! How may I assist you with customer support?\n",
            "Human: My TV is not working.\n",
            "AI:  Ok. It looks like you may have an issue with the power supply or the TV itself. To better assist you, can you tell me the make and model of your TV?\n",
            "\n",
            "User: When I turn it on it makes some weird sounds and then goes black\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I understand. It's possible that your TV may be experiencing a power supply issue. Would you like to test if it is the power supply?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bcb744-6cc6-4949-e8ea-f0430ee1faf0",
        "id": "afMEzKtGtXg7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: My TV is not working.\n",
            "AI:  Ok. It looks like you may have an issue with the power supply or the TV itself. To better assist you, can you tell me the make and model of your TV?\n",
            "Human: When I turn it on it makes some weird sounds and then goes black\n",
            "AI:  I understand. It's possible that your TV may be experiencing a power supply issue. Would you like to test if it is the power supply?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Conversation with ConversationSummaryBufferMemory\n",
        "\n",
        "It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both."
      ],
      "metadata": {
        "id": "IG9kPvWHuQ6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "alYXXicIuQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 200},\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "-NFtobEBuQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting k=2, will only keep the last 2 interactions in memory\n",
        "# max_token_limit=40 - token limits needs transformers installed\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=40)\n"
      ],
      "metadata": {
        "id": "zz-5UGw6uQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary = ConversationChain(\n",
        "    prompt=PROMPT,\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "Bb2u6SQ6uQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"Hi there! I am Sam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597,
          "referenced_widgets": [
            "9cf5c18a89f34b7ca7facee516f6ea75",
            "be7bd377d82342779c2e197b62130585",
            "adebf09c90044b6abcca1836547d9e73",
            "85689ae6091948c593de017fa9e256e0",
            "762dc9c4b3ac449ebe02c38e39fa0df9",
            "c194f26a7fce41fc9cd02f063d3f545d",
            "52a58ce961f34b40a0a1d9ee7fc78762",
            "b9f82ac9194b44ae9ef271f15ffdef76",
            "2f59dadbdd624f30bf5a2039e6fd46ca",
            "f071973c82a94e52b3ce04d0f6a35867",
            "7212e6d03dd9431b84fe49363a1baba7",
            "2b93967aa32140739540fed83e332620",
            "fed334e7aaa4423680793a9d8b0a4bf7",
            "00d4c258773a45e79d5deacbf7d240d2",
            "62414cbb8f0742589bc26f878df1dff9",
            "359c088063904f3ea64ad6b3bbaa79db",
            "9aeea062dd3541c0b88d897453d46a11",
            "c857b63697bd4ffca7aa881777a85a21",
            "8f015ddbac334be4b2fe900a52e67edc",
            "b428eeb217654e2585a4a38d4b655040",
            "a0187d200ad14b9f9e230677c4882b68",
            "40b53401880a4b83bd81c4167f9a9c09",
            "4e174d37fd0c4b329e554e9d92e38755",
            "63987d779af3431b8e4ad1eae4685c5a",
            "2ce771a48465485db7145ad155bcc5c1",
            "5d04f8ac11e2400a91235dbedd9ee7a2",
            "9f59c727eb5b4e239aec229593f3feb2",
            "e52950efdd994cd8ab0f64819e3bbb1f",
            "e037ae48af064da29209294761bd92a7",
            "3cbb335fefff481786bdda367393f7be",
            "aa3f5d6ee25046d99a2c0d1aebc6a158",
            "8058e46c59d543bd82d0ff4212fa9728",
            "ec4a35a8d44d428d8adf8bc167cf2d69",
            "d4f0ed85e4924ebcb6fcdd4be37a7898",
            "6bc9c8426631476e86247b069b749b39",
            "fce5e46db1af451bb350290f934139c8",
            "f1fd7d81e44c470085b3c6de193369b8",
            "babd3f1009734ae7b21145b9fa12c7ea",
            "86f08bf161b34865b58f1962aa56143e",
            "dd203959fbdf4922ad66679f4ce0ca85",
            "e92205189b2c4674af61e6b1fd72d3fb",
            "e491fef0ce7b476d8b1fec00b0b94130",
            "f1340225a3c84bbb96a9f1970fc287da",
            "2c78203f6c4846dea4db8add44c19b88",
            "2827ced6067948828b928fec978fe7be",
            "d7f8d42036b34f58a661f2b56e12a28f",
            "9d4dec11925041639283f8480c273db5",
            "4fb8a321ea5a4910a2551644f60d6c36",
            "785318e4c3dc4f74953884296d782b30",
            "b0728a056b524041a5e6432f2f856fa2",
            "7512967156314d1ca6a32e4a29c14079",
            "57374d7da32a48f9a4aa31b7155f5b93",
            "e0cc846564954fceb2d92b0813e40e9c",
            "b8c45cb9cbe14f618d9e3ec5f1a1f23b",
            "5f8e5d363aa64e168bab94468d150d55"
          ]
        },
        "outputId": "5a5b4943-bfbb-4900-ece1-14727fc0818c",
        "id": "dVHk9ONEuQ6t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Hi there! I am Sam\n",
            "Bot:\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cf5c18a89f34b7ca7facee516f6ea75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b93967aa32140739540fed83e332620"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e174d37fd0c4b329e554e9d92e38755"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4f0ed85e4924ebcb6fcdd4be37a7898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2827ced6067948828b928fec978fe7be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hi Sam, how may I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"I need help with my broken TV\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e5679baf-66c2-45f0-90b2-ac25cbf1b21c",
        "id": "MwIWdc57uQ6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there! I am Sam\n",
            "AI:  Hi Sam, how may I help you today?\n",
            "\n",
            "User: I need help with my broken TV\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Sorry to hear that you are facing an issue with your TV. Let me know what the problem is, and I will do my best to assist you.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "0057495a-3114-494e-ada2-b096dee734f3",
        "id": "sGEjep9zuQ6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "Sam needs help with his broken TV and asks for AI's assistance.\n",
            "AI:  Sorry to hear that you are facing an issue with your TV. Let me know what the problem is, and I will do my best to assist you.\n",
            "\n",
            "User: It makes weird sounds when i turn it on and then goes black\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" There are a few things you can try to resolve this issue. First, please make sure that all the connections are securely attached to your TV and that the power source is working properly.\\n\\nCheck the TV's power cord and ensure it's securely plugged into a functioning power outlet. If the power cord is damaged or frayed, consider replacing it.\\n\\nAlso, try switching out the power source or using a different electrical outlet to see if the problem persists. If it does, the issue may be with the TV's internal components.\\n\\nLet me know if any of these steps resolve the issue.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"It seems to be Hardware\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "1d507edd-44b0-44ae-9e84-c871c7bf1d62",
        "id": "vC9pHPgTuQ6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "System: \n",
            "Sam's TV is not working properly and needs to be fixed. AI offers to help and suggests checking the connections and power source first. If the problem persists, AI suggests switching out the power source or using a different electrical outlet.\n",
            "\n",
            "User: It seems to be Hardware\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Is your TV working properly now?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_with_summary.memory.moving_summary_buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b0deee-60ca-4316-8971-873ae33a41af",
        "id": "GfmR1ypNuQ6u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sam's TV is not working properly and needs to be fixed. AI offers to help and suggests checking the connections and power source first. If the problem persists, AI suggests switching out the power source or using a different electrical outlet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Conversation with Conversation Knowledge Graph Memory"
      ],
      "metadata": {
        "id": "cVFzMuHhvRd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This uses a knowledge graph to recreate memory. The graph consists of some keywords that are related to each other."
      ],
      "metadata": {
        "id": "1PJFUcvqmWxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversation.memory import ConversationKGMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "adK3Chv6vReJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 200},\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "MlhVMDbsvReJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"System: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
        "The assistant is talkative and provides lots of specific details from its context.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "\n",
        "User: {input}\n",
        "Bot:\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
        ")"
      ],
      "metadata": {
        "id": "g2VjzGP1rZQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=prompt,\n",
        "    memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "bMRt3eMdvReJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"Hi there! I am Sam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "5635570f-1b4a-4ab5-f08b-d99f4a54f9c2",
        "id": "X6_ptbbCvReJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Hi there! I am Sam\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hello Sam, nice to meet you!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"My TV is broken and I need some customer assistance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "ad7cdabd-1c19-4dfe-bf9a-99923d82ae28",
        "id": "6kZFM_YqvReJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: My TV is broken and I need some customer assistance\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I'm here to help! What seems to be the issue?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ed8fd57f-c847-4828-c66d-4ddde6e7a419",
        "id": "1mYBMM3CvReK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: It makes weird sounds when i turn it on and then goes black\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hey there, we appreciate your inquiry! I'm sorry to hear about the trouble you're having. Could you tell me a bit more about what you're experiencing? How long has the TV been acting up, and what does it do?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_kg.predict(input=\"Yes it's been acting like that since two weeks and it is still under warranty. my warranty number is A512423\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "42769eea-65d8-437b-fac1-a636e196c775",
        "id": "bHaY4eQovReK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a knowledgeable helpful assistant and a customer.\n",
            "The assistant is talkative and provides lots of specific details from its context.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "User: Yes it's been acting like that since two weeks and it is still under warranty. my warranty number is A512423\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" That's an excellent number, thank you for that information. May you please provide me with your address so that I can look for it in our system?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NetworkX Entity graph\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nx.draw(conversation_with_kg.memory.kg, with_labels=True)\n",
        "# plt.show()\n",
        "\n",
        "print(conversation_with_kg.memory.kg)\n",
        "print(conversation_with_kg.memory.kg.get_triples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1100982-7e67-4ac7-bd59-0c4ddbfa2744",
        "id": "pc8XWyGIvReK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain_community.graphs.networkx_graph.NetworkxEntityGraph object at 0x7fe50bfdbf70>\n",
            "[('TV', 'goes black', 'makes weird sounds')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity Memory"
      ],
      "metadata": {
        "id": "fjqlw-Q2HDLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the facts we supply initially, it extracts information on entities. In the later conversations, it provides response based on the knowledge it has built."
      ],
      "metadata": {
        "id": "BjyfeP-J_68D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
        "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any"
      ],
      "metadata": {
        "id": "Ud227jNMHEtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Bedrock(\n",
        "    credentials_profile_name=credentials, model_id=\"amazon.titan-text-lite-v1\", region_name=\"ap-southeast-2\",\n",
        "    model_kwargs={\"temperature\": 1, \"maxTokenCount\": 256},\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "8bwvmRCtHPmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationEntityMemory(llm=llm)"
      ],
      "metadata": {
        "id": "0UbTWQyNzV2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## The propmpt\n",
        "ENTITY_MEMORY_CONVERSATION_TEMPLATE.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "hWZneigxHwd0",
        "outputId": "7c1aefeb-f61a-4737-b3ad-27cd81bfd4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"System: You are an assistant to a human, powered by a large language model. You are designed to be able to assist\n",
        "with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics.\n",
        "As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding\n",
        "conversations and provide responses that are coherent and relevant to the topic at hand. You are constantly learning and improving, and\n",
        "your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to\n",
        "provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by\n",
        "the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing\n",
        "you to engage in discussions and provide explanations and descriptions on a wide range of topics. Overall, you are a powerful tool\n",
        "that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs\n",
        "help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
        "\n",
        "Context:\n",
        "{entities}\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "\n",
        "Last line:\n",
        "User: {input}\n",
        "Bot:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
        ")\n",
        "\n",
        "ENTITY_MEMORY_CONVERSATION_TEMPLATE = PROMPT"
      ],
      "metadata": {
        "id": "WFijycwv2wdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "cXd58z9dHVxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"John & Sam are working on a startup.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "-PhxTkMuHWUN",
        "outputId": "9ad5e3cd-1861-4c9d-dc55-cf0a726cc986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are an assistant to a human, powered by a large language model. You are designed to be able to assist \n",
            "with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \n",
            "As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding \n",
            "conversations and provide responses that are coherent and relevant to the topic at hand. You are constantly learning and improving, and \n",
            "your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to \n",
            "provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by \n",
            "the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing \n",
            "you to engage in discussions and provide explanations and descriptions on a wide range of topics. Overall, you are a powerful tool \n",
            "that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs \n",
            "help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'John': '', 'Sam': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "Last line:\n",
            "User: John & Sam are working on a startup.\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" What's a startup?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"They are trying to create a simplicity in the transport system.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "Osa-NHDtJxUW",
        "outputId": "255d4f32-bdff-4357-ffb6-669c385ac76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are an assistant to a human, powered by a large language model. You are designed to be able to assist \n",
            "with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \n",
            "As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding \n",
            "conversations and provide responses that are coherent and relevant to the topic at hand. You are constantly learning and improving, and \n",
            "your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to \n",
            "provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by \n",
            "the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing \n",
            "you to engage in discussions and provide explanations and descriptions on a wide range of topics. Overall, you are a powerful tool \n",
            "that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs \n",
            "help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'John': 'John is working on a startup with Sam.', 'Sam': 'Sam is helping John & Sam work on a startup.', 'startup': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: John & Sam are working on a startup.\n",
            "AI:  What's a startup?\n",
            "\n",
            "Last line:\n",
            "User: They are trying to create a simplicity in the transport system.\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Good, do you need any help?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"They are a pioneer of building electric motors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "nACGS-DF5Itm",
        "outputId": "8e1a5f06-0230-4578-bb5b-2d34a3b03a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are an assistant to a human, powered by a large language model. You are designed to be able to assist \n",
            "with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \n",
            "As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding \n",
            "conversations and provide responses that are coherent and relevant to the topic at hand. You are constantly learning and improving, and \n",
            "your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to \n",
            "provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by \n",
            "the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing \n",
            "you to engage in discussions and provide explanations and descriptions on a wide range of topics. Overall, you are a powerful tool \n",
            "that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs \n",
            "help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Pioneer': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: John & Sam are working on a startup.\n",
            "AI:  What's a startup?\n",
            "Human: They are trying to create a simplicity in the transport system.\n",
            "AI:  Good, do you need any help?\n",
            "\n",
            "Last line:\n",
            "User: They are a pioneer of building electric motors.\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Oh I see. Are you interested in electric motors?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Who is John?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "0DOI2v7q-25V",
        "outputId": "a6bb1815-e907-44a8-8acf-639c98d52d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are an assistant to a human, powered by a large language model. You are designed to be able to assist \n",
            "with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. \n",
            "As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding \n",
            "conversations and provide responses that are coherent and relevant to the topic at hand. You are constantly learning and improving, and \n",
            "your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to \n",
            "provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by \n",
            "the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing \n",
            "you to engage in discussions and provide explanations and descriptions on a wide range of topics. Overall, you are a powerful tool \n",
            "that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs \n",
            "help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'John': 'John is working on a startup with Sam to create a simplicity in the transport system.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: John & Sam are working on a startup.\n",
            "AI:  What's a startup?\n",
            "Human: They are trying to create a simplicity in the transport system.\n",
            "AI:  Good, do you need any help?\n",
            "Human: They are a pioneer of building electric motors.\n",
            "AI:  Oh I see. Are you interested in electric motors?\n",
            "\n",
            "Last line:\n",
            "User: Who is John?\n",
            "Bot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' John is the CEO of the company and works together with Sam to create a simplicity in the transport system.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.memory.entity_cache"
      ],
      "metadata": {
        "id": "yKn0evo4KqnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c8df9e-2920-4d95-a6cf-673af66ea87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John']"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duh46CpJKyRz",
        "outputId": "629f91fc-4c3c-4874-f3bc-0fe5f620638d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'John': 'John is the CEO of a company, he is working together with Sam to '\n",
            "         'create a simplicity in the transport system.',\n",
            " 'Pioneer': 'John & Sam are pioneers of building electric motors.',\n",
            " 'Sam': 'Sam is working on a startup with John to create simplicity in the '\n",
            "        'transport system.',\n",
            " 'startup': 'Startup is a business that creates a simple transport system.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CF1p0Gcp7Uai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}